{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 13: Final Project\n",
    "\n",
    "## Intro to Quantified Cognition\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/compmem/QuantCog/blob/2021_Spring/notebooks/13_Final_Project.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final Project\n",
    "\n",
    "- The goal of the final project is to demonstrate some application of some of the modeling tools we've discussed this semester. \n",
    "\n",
    "- Unless you are developing a novel theory, most mechanistic cognitive modeling involves making use of an existing model, which you then may tweak for your needs/hypotheses.\n",
    "\n",
    "- We've covered a handful of different cognitive models this semester, with code included in various Jupyter notebooks along the way, so you have a number of ready-made models at your disposal.\n",
    "\n",
    "- Below I list some options for this final project:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## General Info\n",
    "\n",
    "- Please turn in the project in the form of a Jupyter notebook, along with any other files I might need to run the notebook. You don't need to send me the data files I provided to you, just if you used your own data/code.\n",
    "\n",
    "- Show all your work and include both code and text cells walking me through what you are doing.\n",
    "\n",
    "- It is due ***Friday, May 14th, 2021*** at 11:59 PM. I selected this date because it's the day of our final, near the last day of exams, and I need to have final grades soon after that.\n",
    "\n",
    "- I will be available for meetings from now until it is due. Please slack me to schedule one.\n",
    "\n",
    "- You can talk to each other, but please make sure you each turn in a final project and that you have done the primary analysis and interpretation on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 0: Some analysis of your own data\n",
    "\n",
    "Many of you have datasets from your own research. Your project would entail performing some form of Bayesian or cognitive model-based analysis of those data. \n",
    "\n",
    "Note, it would be acceptable to use PyMC3 and build a Bayesian model to generate your data, as long as we have not performed the specific analysis already in class.\n",
    "\n",
    "You must include the following:\n",
    "\n",
    "- A short intro (a couple sentences) explaining the question you'll be asking (to frame the analysis)\n",
    "- Test some alternative model variants\n",
    "- Some form of model comparison (via Bayes Factor, BPIC, WAIC, etc...)\n",
    "- Show model fit (at least best-fitting params, but potentially posterior predictives)\n",
    "- Summary of findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 1: Generating Model Contest\n",
    "\n",
    "Very often we have some data and our goal is to identify what model might have generated those data. For this project, I have generated three sets of data with three different decision models: WFPT, TRDM, and LBA. \n",
    "\n",
    "Your job is to fit models (and model varariants with and without some params free, such as between-trial variability in drift rate) to identify what models (and parameter values, as best fits or posteriors) were used to generate each set of data.\n",
    "\n",
    "This will require model comparison, via some method of your choosing (Bayes Factor, BPIC, WAIC, etc...).\n",
    "\n",
    "In your report, make it clear each model variant you are testing, what model you think generated each dataset (along with the posteriors or best-fitting parameters) for that model, and what evidence you are using to make your claim for the each winning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 2: LBA Model Extension\n",
    "\n",
    "Extend LBA to include generation of a confidence value in addition to the choice and reaction time it already produces. One method of achieving this (though I'm open to other approaches as long as you justify them) is to assume that confidence is directly proportional to the level of activation for the accumulator with the winning choice relative to the sum of all the accumulator activations at that time. \n",
    "\n",
    "Intuitively, this approach makes some sense. If the selected choice has a high level of activation relative to the non-selected choice, then the confidence will be high (close to 1.0). On the other hand, if there is strong evidence for both choices and one just barely wins out over the other, then the ratio of the winning choice to all choices will be closer to .5 (for the two-choice case).\n",
    "\n",
    "To test whether this model is, indeed, making predictions that make sense, pick the variant of the LBA model that fit best to the speed--accuracy trade-off decision data (the one that allowed the drift rates to change between conditions) and perform the fit again with this new model. Even though you are not fitting to confidence, we can simulate the model with the best-fitting parameters and generate a distribution of confidence values for the speed condition and confidence values for the accuracy condition. \n",
    "\n",
    "Here are some questions to answer in your write-up:\n",
    "\n",
    "- Are people more confident in their correct answers in the accuracy condition than in the speeded condition? Does your result make sense?\n",
    "- Are the confidence values different for correct and incorrect answers? \n",
    "- What would happen to the confidence values (on average) if you added in a third option? (You could even take your best-fitting params and simply add in a third option to the inputs at either low or high levels of input to see what would happen.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 3: Flanker Analysis\n",
    "\n",
    "While there have been full models of cognitive control proposed to account for the dynamics of the decision process in congruent vs. incongruent conditions, insight can be gained by fitting to these two conditions separately with a standard decision-making model.\n",
    "\n",
    "- Fit the WFPT, TRDM, or LBA model separately to the incongruent and congruent trials from the flanker task.\n",
    "- Decide what parameters should be kept constant between the two conditions and what parameters should be allowed to change.\n",
    "- Justify this decision (perhaps even via a model comparison).\n",
    "- Show fits of the best-fitting parameters (or posterior predictives) to the data.\n",
    "- Show full posteriors for the parameters and discuss whether they make sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 4: Apply the Successor Representation model to a new RL Problem\n",
    "\n",
    "In class we applied the successor representation (SR) to the Frozen Lake example provided by the OpenAI Gym (https://gym.openai.com/envs/FrozenLake8x8-v0/). We did not show a successful demonstration of the SR solving the problem when `slippery` was set to `True`. The issue there was that there was a *lot* of noise in the movements that came from adding the random variability. \n",
    "\n",
    "For this option, your task would be to apply the SR to an RL problem that we did not already solve. Some options would be:\n",
    "\n",
    "- The Frozen Lake example with the slippery option turned on. For this you'd likely need to modify the model to include more sources of variability or else the agent will get stuck exploiting a bad option.\n",
    "\n",
    "- Another one of the text-based environments on the OpenAI Gym: https://gym.openai.com/envs/#toy_text\n",
    "  The reason to use the text-based environments is that they have lower numbers of states that do not require deep convolutional networks to define. \n",
    "  \n",
    "- Some other problem that you propose. I'm happy to work with you to decide on another problem you'd like to apply the SR (or some other RL-model) to solve.\n",
    "\n",
    "In your write-up, be sure to clearly define your problem, how you assessed model performance (e.g., reward earned for each game, etc...), describe what changes you had to make to the parameters to attain the performance you did, and, optionally, explore the effect different model parameters have on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Option 5: Explore TCM variants for the CatCR task\n",
    "\n",
    "For the example in class, I presented one model variant of a temporal context model (TCM) applied to the categorical continuous recognition (CatCR) data. There are a number of valid model variants that may or may not provide a better fit to the observed data.\n",
    "\n",
    "For this option, you would explore some of those model variants and perform a model comparison on one subject (Subject 10) that showed the interesting trend in the data we saw across participants. Some options include:\n",
    "\n",
    "- Changing how the sources of memory strength are calculated.\n",
    "- Trying variants of how distinctiveness is calculated.\n",
    "- Adding in a WFPT, TRDM, or LBA decision rule to replace the softmax (if you choose this one, it would be the only model you have to try, but bonus for comparing different choice/RT decision rules!)\n",
    "\n",
    "I will gladly meet with you to discuss interesting model variants to try out.\n",
    "\n",
    "In your write-up, be sure to describe the motivation for each model variant (i.e., what is the explicit mechanistic hypothesis you are testing?), and, where applicable, perform model comparisons. Include fits to the actual data (best-fitting parameters are fine, given that this model is slower to run.) "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
